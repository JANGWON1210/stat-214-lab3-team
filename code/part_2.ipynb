{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Modeling and Evaluation\n",
    "\n",
    "In this section, we use the lagged embeddings created in Part 1 (Bag-of-Words, Word2Vec, and GloVe) to build predictive models of brain activity using fMRI voxel data.\n",
    "\n",
    "We follow these key steps:\n",
    "1. Load and validate the preprocessed embeddings (X) for each story.\n",
    "2. Load corresponding fMRI response matrices (Y) for each subject.\n",
    "3. Fit a ridge regression model for each embedding type to predict Y from X.\n",
    "4. Compute the mean correlation coefficient (CC) across all voxels to evaluate model performance.\n",
    "5. Save the trained models and the evaluation metrics for further analysis.\n",
    "\n",
    "Each embedding is evaluated on the same story to ensure consistency across comparisons.\n",
    "This part prepares the ground for more advanced evaluation, such as voxel-level analysis and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, let's load the data and check they are in the right format by checking story timepoint consistency across embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking story timepoint consistency across embeddings...\n",
      "\n",
      "All stories have consistent timepoint lengths across embeddings.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def load_embeddings(data_dir):\n",
    "    \"\"\"Load all three types of embedding data into a dictionary.\"\"\"\n",
    "    X_bow = joblib.load(data_dir / \"X_lagged_BoW.joblib\")\n",
    "    with open(data_dir / \"X_lagged_W2V.pkl\", \"rb\") as f:\n",
    "        X_w2v = pickle.load(f)\n",
    "    with open(data_dir / \"X_lagged_GloVe.pkl\", \"rb\") as f:\n",
    "        X_glove = pickle.load(f)\n",
    "    return {\"BoW\": X_bow, \"Word2Vec\": X_w2v, \"GloVe\": X_glove}\n",
    "\n",
    "def check_timepoint_consistency(embeddings):\n",
    "    \"\"\"Check if timepoint lengths match across BoW, Word2Vec, and GloVe for each story.\"\"\"\n",
    "    print(\"Checking story timepoint consistency across embeddings...\\n\")\n",
    "    story_set = set(embeddings[\"BoW\"]) & set(embeddings[\"Word2Vec\"]) & set(embeddings[\"GloVe\"])\n",
    "    mismatches = []\n",
    "\n",
    "    for story in sorted(story_set):\n",
    "        l_bow = embeddings[\"BoW\"][story].shape[0]\n",
    "        l_w2v = embeddings[\"Word2Vec\"][story].shape[0]\n",
    "        l_glove = embeddings[\"GloVe\"][story].shape[0]\n",
    "\n",
    "        if not (l_bow == l_w2v == l_glove):\n",
    "            mismatches.append((story, l_bow, l_w2v, l_glove))\n",
    "\n",
    "    if mismatches:\n",
    "        print(\"Found mismatches in the following stories:\")\n",
    "        for story, l_b, l_w, l_g in mismatches:\n",
    "            print(f\"- {story}: BoW={l_b}, Word2Vec={l_w}, GloVe={l_g}\")\n",
    "    else:\n",
    "        print(\"All stories have consistent timepoint lengths across embeddings.\")\n",
    "\n",
    "# === Run check ===\n",
    "DATA_DIR = Path(\"../data\")\n",
    "embeddings = load_embeddings(DATA_DIR)\n",
    "check_timepoint_consistency(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All stories have matching timepoint lengths across embeddings.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/processed/sub-01/func/sub-01_task-tasks_bold_space-MNI152NLin2009cAsym_desc-preproc_timeseries_voxels.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    102\u001b[39m subject_id = \u001b[33m\"\u001b[39m\u001b[33m01\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# change as needed\u001b[39;00m\n\u001b[32m    103\u001b[39m story_name = \u001b[33m\"\u001b[39m\u001b[33msweetaspie\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# change as needed\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstory_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(subject_id, story_name)\u001b[39m\n\u001b[32m     64\u001b[39m embeddings = load_embeddings()\n\u001b[32m     65\u001b[39m validate_embedding_lengths(embeddings)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m Y_full = \u001b[43mload_fmri_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m results = {}\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m emb_name, emb_data \u001b[38;5;129;01min\u001b[39;00m embeddings.items():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mload_fmri_data\u001b[39m\u001b[34m(subject_id)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load fMRI voxel data for the given subject.\"\"\"\u001b[39;00m\n\u001b[32m     26\u001b[39m voxel_path = DATA_DIR / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mprocessed/sub-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/func/sub-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_task-tasks_bold_space-MNI152NLin2009cAsym_desc-preproc_timeseries_voxels.npy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m Y = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvoxel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/anaconda3/envs/stat214/lib/python3.12/site-packages/numpy/lib/npyio.py:427\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    425\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    426\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    428\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/processed/sub-01/func/sub-01_task-tasks_bold_space-MNI152NLin2009cAsym_desc-preproc_timeseries_voxels.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "from pathlib import Path\n",
    "\n",
    "# Define file paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "RESULTS_DIR = Path(\"../results\")\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Load embeddings (X)\n",
    "def load_embeddings():\n",
    "    \"\"\"Load embeddings from previously processed files.\"\"\"\n",
    "    X_bow = joblib.load(DATA_DIR / \"X_lagged_BoW.joblib\")\n",
    "    with open(DATA_DIR / \"X_lagged_W2V.pkl\", \"rb\") as f:\n",
    "        X_w2v = pickle.load(f)\n",
    "    with open(DATA_DIR / \"X_lagged_GloVe.pkl\", \"rb\") as f:\n",
    "        X_glove = pickle.load(f)\n",
    "    return {\"BoW\": X_bow, \"Word2Vec\": X_w2v, \"GloVe\": X_glove}\n",
    "\n",
    "# Load fMRI data (Y)\n",
    "def load_fmri_data(subject_id):\n",
    "    \"\"\"Load fMRI voxel data for the given subject.\"\"\"\n",
    "    voxel_path = DATA_DIR / f\"processed/sub-{subject_id}/func/sub-{subject_id}_task-tasks_bold_space-MNI152NLin2009cAsym_desc-preproc_timeseries_voxels.npy\"\n",
    "    Y = np.load(voxel_path)\n",
    "    return Y\n",
    "\n",
    "# Fit ridge regression and calculate mean correlation coefficient (CC)\n",
    "def fit_ridge_and_eval(X, Y, alpha=1.0):\n",
    "    \"\"\"Fit ridge regression and compute mean correlation coefficient.\"\"\"\n",
    "    model = Ridge(alpha=alpha)\n",
    "    model.fit(X, Y)\n",
    "    Y_pred = model.predict(X)\n",
    "    cc = np.mean([np.corrcoef(Y[:, i], Y_pred[:, i])[0, 1] for i in range(Y.shape[1])])\n",
    "    return model, cc\n",
    "\n",
    "# Main pipeline for ridge regression per embedding\n",
    "def main(subject_id, story_name):\n",
    "    \"\"\"Main function to fit ridge regression model for different embeddings and evaluate.\"\"\"\n",
    "\n",
    "    embeddings = load_embeddings()\n",
    "    Y_full = load_fmri_data(subject_id)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for emb_name, emb_data in embeddings.items():\n",
    "        print(f\"Processing embedding: {emb_name}\")\n",
    "        X_story = emb_data[story_name]\n",
    "\n",
    "        # Ensure X and Y dimensions match\n",
    "        T = min(X_story.shape[0], Y_full.shape[0])\n",
    "        X = X_story[:T, :]\n",
    "        Y = Y_full[:T, :]\n",
    "\n",
    "        print(f\"Shapes after matching: X {X.shape}, Y {Y.shape}\")\n",
    "\n",
    "        # Fit Ridge Regression\n",
    "        model, mean_cc = fit_ridge_and_eval(X, Y)\n",
    "\n",
    "        print(f\"Mean CC for {emb_name}: {mean_cc:.4f}\")\n",
    "        results[emb_name] = mean_cc\n",
    "\n",
    "        # Save trained model\n",
    "        model_path = RESULTS_DIR / f\"ridge_model_{emb_name}_{story_name}.pkl\"\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"Saved model to {model_path}\")\n",
    "\n",
    "    # Save mean CC results\n",
    "    cc_results_path = RESULTS_DIR / f\"mean_cc_{story_name}.pkl\"\n",
    "    with open(cc_results_path, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"Saved CC results to {cc_results_path}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    subject_id = \"01\"  # change as needed\n",
    "    story_name = \"sweetaspie\"  # change as needed\n",
    "    main(subject_id, story_name)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat214",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
